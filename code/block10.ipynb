{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf39533",
   "metadata": {},
   "source": [
    "# Binary Classifier Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba2705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lr_model_jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf3a3f",
   "metadata": {},
   "source": [
    "## Trying Out the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcaa6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some dummy observations and predictions\n",
    "y_actual = np.array([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]) # N\n",
    "y_pred = np.array([0.06, 0.92, 0.86, 0.03, 0.40, 0.70, 0.23, 0.4, 0.2, 0.8, 0.9, 0.65, 0.75, 0.4]) # N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073e840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7142857142857143\n",
      "Accuracy (Null)  0.6428571428571429\n",
      "Balanced Accuracy  0.7333333333333334\n",
      "Balanced Accuracy (Null)  0.5\n",
      "Recall  0.6666666666666666\n",
      "Recall (Ones all the time)  1.0\n",
      "Precision  0.8571428571428571\n",
      "Precision (Ones all the time)  0.6428571428571429\n",
      "Precision (Trivial)  1.0\n",
      "F1  0.75\n",
      "F1 (Ones all the time) 0.782608695652174\n",
      "AUC-ROC  0.7555555555555555\n",
      "AUC-PR  0.8063492063492064\n",
      "AUC-PR (Null)  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "# accuracy, notice that we have to threshold\n",
    "print(\"Accuracy \", sklearn.metrics.accuracy_score(y_actual, y_pred > 0.5))\n",
    "\n",
    "# accuracy under null model\n",
    "# in real world, the mean would be based on TRAINING set\n",
    "null_ypred = np.mean(y_actual) * np.ones_like(y_actual)\n",
    "print(\"Accuracy (Null) \", sklearn.metrics.accuracy_score(y_actual, null_ypred > 0.5))\n",
    "\n",
    "# balanced accuracy\n",
    "print(\"Balanced Accuracy \", sklearn.metrics.balanced_accuracy_score(y_actual, y_pred > 0.5))\n",
    "\n",
    "print(\"Balanced Accuracy (Null) \", sklearn.metrics.balanced_accuracy_score(y_actual, null_ypred > 0.5))\n",
    "\n",
    "\n",
    "# recall\n",
    "print(\"Recall \", sklearn.metrics.recall_score(y_actual, y_pred > 0.5))\n",
    "\n",
    "# recall when saying yes all the time\n",
    "print(\"Recall (Ones all the time) \", sklearn.metrics.recall_score(y_actual, np.ones_like(y_actual)))\n",
    "\n",
    "# precision\n",
    "print(\"Precision \", sklearn.metrics.precision_score(y_actual, y_pred > 0.5))\n",
    "\n",
    "# precision when saying yes all the time\n",
    "print(\"Precision (Ones all the time) \", sklearn.metrics.precision_score(y_actual, np.ones_like(y_actual)))\n",
    "\n",
    "\n",
    "# precision when predicting one positive example that happens to be correct\n",
    "yhat = np.zeros_like(y_actual)\n",
    "yhat[1] = 1\n",
    "print(\"Precision (Trivial) \", sklearn.metrics.precision_score(y_actual, yhat))\n",
    "\n",
    "# f1 score\n",
    "print(\"F1 \", sklearn.metrics.f1_score(y_actual, y_pred > 0.5))\n",
    "print(\"F1 (Ones all the time)\", sklearn.metrics.f1_score(y_actual, np.ones_like(y_actual)))\n",
    "\n",
    "# AUC-ROC, notice: no thresholding\n",
    "print(\"AUC-ROC \", sklearn.metrics.roc_auc_score(y_actual, y_pred))\n",
    "print(\"AUC-PR \", sklearn.metrics.average_precision_score(y_actual, y_pred))\n",
    "print(\"AUC-PR (Null) \", sklearn.metrics.average_precision_score(y_actual, np.mean(y_actual) * np.ones_like(y_actual)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc326d2",
   "metadata": {},
   "source": [
    "## Applying to Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9583a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmkhajah/Projects/python-ml-2025/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.553,\n",
       " 'accuracy_null': 0.5,\n",
       " 'balanced_accuracy': 0.5529999999999999,\n",
       " 'balanced_accuracy_null': 0.5,\n",
       " 'recall': 0.6,\n",
       " 'recall_null': 0.0,\n",
       " 'precision': 0.5484460694698354,\n",
       " 'precision_null': 0.0,\n",
       " 'f1': 0.5730659025787965,\n",
       " 'f1_null': 0.0,\n",
       " 'auc_roc': 0.547216,\n",
       " 'auc_pr': 0.46840853414104267,\n",
       " 'auc_pr_null': 0.5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/nonseparable_binary_data.csv\")\n",
    "rng = jax.random.key(42)\n",
    "best_Beta = lr_model_jax.optimize(rng,\n",
    "                                  input_df = df[['x1','x2']],\n",
    "                                  y = df.y.to_numpy(),\n",
    "                                  learning_rate = 0.1,\n",
    "                                  epochs = 100)\n",
    "yhat = lr_model_jax.predict(Beta = best_Beta, input_df = df[['x1','x2']])\n",
    "\n",
    "mu = np.mean(df.y)\n",
    "\n",
    "# null model prediction\n",
    "yhat_null = mu * np.ones(df.shape[0])\n",
    "\n",
    "# hard decisions ...\n",
    "threshold = 0.5 \n",
    "yhat_hard = yhat > threshold\n",
    "yhat_null_hard = yhat_null > threshold\n",
    "\n",
    "ytrue = df.y.to_numpy()\n",
    "\n",
    "dict(\n",
    "    accuracy = sklearn.metrics.accuracy_score(ytrue, yhat_hard),\n",
    "    accuracy_null = sklearn.metrics.accuracy_score(ytrue, yhat_null_hard),\n",
    "    \n",
    "    balanced_accuracy = sklearn.metrics.balanced_accuracy_score(ytrue, yhat_hard),\n",
    "    balanced_accuracy_null = sklearn.metrics.balanced_accuracy_score(ytrue, yhat_null_hard),\n",
    "\n",
    "    recall = sklearn.metrics.recall_score(ytrue, yhat_hard),\n",
    "    recall_null = sklearn.metrics.recall_score(ytrue, yhat_null_hard),\n",
    "\n",
    "    precision = sklearn.metrics.precision_score(ytrue, yhat_hard),\n",
    "    precision_null = sklearn.metrics.precision_score(ytrue, yhat_null_hard),\n",
    "\n",
    "    f1 = sklearn.metrics.f1_score(ytrue, yhat_hard),\n",
    "    f1_null = sklearn.metrics.f1_score(ytrue, yhat_null_hard),\n",
    "\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(ytrue, yhat),\n",
    "    auc_pr = sklearn.metrics.average_precision_score(ytrue, yhat),\n",
    "    auc_pr_null = sklearn.metrics.average_precision_score(ytrue, yhat_null),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b0077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-ml-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
