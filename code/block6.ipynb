{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffd671c",
   "metadata": {},
   "source": [
    "# Block 6: Feature Selection\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Learn about functions as first class objects \n",
    "- Implement CV function\n",
    "- Implement and test brute force selection\n",
    "- Implement and test forward greedy selection\n",
    "- Use brute force and greedy within the proper nested-CV setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ee049e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import itertools\n",
    "from typing import List\n",
    "import linear_model_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671f972",
   "metadata": {},
   "source": [
    "## Functions are First Class Objects in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02953624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "13\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# consider this simple function\n",
    "def myfunc(a, b):\n",
    "    return a + b\n",
    "\n",
    "print(myfunc(3, 5)) # prints 8\n",
    "\n",
    "# we can \"wrap\" the function within another function:\n",
    "# this function returns another function! just like any other value!\n",
    "def wrapper():\n",
    "    def wrapped(a, b):\n",
    "        return a + b \n",
    "    return wrapped \n",
    "\n",
    "myfunc = wrapper() # myfunc is now assigned to the function that was returned from wrapper()\n",
    "\n",
    "print(myfunc(3, 5)) # 8\n",
    "print(wrapper()(3, 5)) # same thing\n",
    "\n",
    "# so what is the point? we just did the same thing in a more complicated way!\n",
    "# the point is that you can pass arguments to the wrapper that will always be available to the wrapped\n",
    "\n",
    "def wrapper(a):\n",
    "    def wrapped(b):\n",
    "        return a + b \n",
    "    return wrapped\n",
    "\n",
    "myfunc = wrapper(10) # my func is a function that takes on argument and adds 10 to it\n",
    "\n",
    "print(myfunc(3))\n",
    "print(myfunc(-10))\n",
    "\n",
    "# This is why functions are first class objects: you can pass them around, return them, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f0a570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closure time!\n",
    "# we will create a function that returns the mvlr_train_test_fn, but with the input and output columns defined\n",
    "# we can call this a factory\n",
    "def mvlr_train_test_function_factory(input_cols, output_col):\n",
    "    def train_test_fn(train_df, test_df):\n",
    "        return linear_model_numpy.mvlr_train_test_function(train_df, test_df, input_cols, output_col)\n",
    "    return train_test_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7a5c7",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "336c5fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (406, 9)\n",
      "After:  (392, 9)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_json('../data/cars.json')\n",
    "\n",
    "# Filter dataframe\n",
    "required_cols = ['Miles_per_Gallon', 'Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin']\n",
    "\n",
    "# only include rows where ALL columns are not nan\n",
    "ix_included = np.sum(pd.isna(df[required_cols]), axis=1) == 0\n",
    "\n",
    "# exclude examples with no horsepower or mpg\n",
    "print(\"Before: \", df.shape)\n",
    "df = df[ix_included]\n",
    "print(\"After: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983275ce",
   "metadata": {},
   "source": [
    "# Create a CV function and test our new factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cecf2cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(18.6710588079303),\n",
       " np.float64(20.827477521411375),\n",
       " np.float64(23.804879577197713),\n",
       " np.float64(21.837305759462094),\n",
       " np.float64(21.32855280367554)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cv(df, train_test_fn, folds, random_state):\n",
    "    \"\"\"\n",
    "        Cross-validation: splits dataset into N folds, repeatedly trains on N-1 folds and test on the remaining.\n",
    "\n",
    "        Inputs:\n",
    "            df: dataframe of inputs and outputs\n",
    "            train_test_fn: the training and testing function used\n",
    "            folds: number of folds\n",
    "            random_state: pseudo random number generator state\n",
    "        Output:\n",
    "            metrics: loss on each split (size N)\n",
    "    \n",
    "    \"\"\"\n",
    "    # instantiate the splitter\n",
    "    kf = sklearn.model_selection.KFold(n_splits=folds, \n",
    "                                       shuffle=True, \n",
    "                                       random_state=random_state)\n",
    "    \n",
    "    metrics = []\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_df = df.iloc[train_index]\n",
    "        test_df = df.iloc[test_index]\n",
    "        \n",
    "        # evaluate\n",
    "        metric = train_test_fn(train_df, test_df)\n",
    "        metrics.append(metric)\n",
    "    \n",
    "    return metrics \n",
    "\n",
    "train_test_fn = mvlr_train_test_function_factory(['Horsepower', 'Cylinders'], 'Miles_per_Gallon') \n",
    "metrics = cv(df, train_test_fn, folds=5, random_state=2342)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab58b7",
   "metadata": {},
   "source": [
    "## Brute Force Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16b9d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a',), ('b',), ('c',)]\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'c')]\n",
      "[('a', 'b', 'c')]\n",
      "[('a',), ('b',), ('c',), ('a', 'b'), ('a', 'c'), ('b', 'c')]\n"
     ]
    }
   ],
   "source": [
    "# let's play with combinations function because we'll use it in brute force\n",
    "# selection\n",
    "cols = ['a', 'b', 'c']\n",
    "\n",
    "# combinations of length 3\n",
    "print(list(itertools.combinations(cols, 1)))\n",
    "# combinations of length 2\n",
    "print(list(itertools.combinations(cols, 2)))\n",
    "# combinations of length 3\n",
    "print(list(itertools.combinations(cols, 3)))\n",
    "\n",
    "# to get all combinations\n",
    "all_combinations = [comb for i in range(1, len(cols)) for comb in itertools.combinations(cols, i)]\n",
    "print(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ae3af3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weight_in_lbs', 'Origin', 'Year']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def brute_force_selection(df,\n",
    "                          input_cols,\n",
    "                          output_col,\n",
    "                          train_test_factory):\n",
    "\n",
    "    # generate all combinations\n",
    "    all_combinations = [comb for i in range(1, len(input_cols)) for comb in itertools.combinations(input_cols, i)]\n",
    "\n",
    "    # start cross validation FOR EACH combination\n",
    "    all_metrics = []\n",
    "    for combination in all_combinations:\n",
    "        \n",
    "        # call our factory to get the train_test_fn\n",
    "        train_test_fn = train_test_factory(list(combination), output_col)\n",
    "\n",
    "        # important to keep random state the same for all combinations\n",
    "        # so that generated splits are the same\n",
    "        metrics = cv(df, train_test_fn, folds=5, random_state=23412341)\n",
    "        all_metrics.append(metrics)\n",
    "    \n",
    "    # organize all results in a 2D matrix (Rows = combinations, cols = folds)\n",
    "    all_metrics = np.array(all_metrics) # Combinations x Folds\n",
    "\n",
    "    # compute average metric for each combination\n",
    "    avg_metric = np.mean(all_metrics, axis=1) # Combinations\n",
    "    \n",
    "    # pick best\n",
    "    best_ix = np.argmin(avg_metric)\n",
    "    best_combination = list(all_combinations[best_ix])\n",
    "    \n",
    "    return best_combination\n",
    "\n",
    "# the features we want to search over ... the more -> the slower the algorithm\n",
    "# if you have K features, the algorithm will examin 2^K - 1 models ... so exponential scaling\n",
    "features = ['Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin', 'Year']\n",
    "\n",
    "best_combination = brute_force_selection(df, input_cols=features, output_col='Miles_per_Gallon', train_test_factory=mvlr_train_test_function_factory)\n",
    "\n",
    "best_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680668a",
   "metadata": {},
   "source": [
    "## Forward Greedy Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "807ec2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weight_in_lbs', 'Year', 'Origin', 'Acceleration', 'Horsepower']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_greedy_selection(df,\n",
    "                             input_cols,\n",
    "                             output_col,\n",
    "                             train_test_factory):\n",
    "    \n",
    "    \n",
    "    current_combination = []\n",
    "    current_metric = np.inf\n",
    "    rem_features = input_cols\n",
    "\n",
    "    while len(rem_features) > 0:\n",
    "        \n",
    "        all_metrics = []\n",
    "        for feature in rem_features:\n",
    "            \n",
    "            # create candidate\n",
    "            candidate_combination = current_combination + [feature]\n",
    "\n",
    "            train_test_fn = train_test_factory(candidate_combination, output_col)\n",
    "\n",
    "\n",
    "            # important to keep random state the same for all combinations\n",
    "            # so that generated splits are the same\n",
    "            metrics = cv(df, train_test_fn, folds=5, random_state=23412341)\n",
    "            all_metrics.append(metrics)\n",
    "        \n",
    "        # organize all results in a 2D matrix (Rows = Rem Features, cols = folds)\n",
    "        all_metrics = np.array(all_metrics) # Rem Features x Folds\n",
    "\n",
    "        # compute average metric for each combination\n",
    "        avg_metric = np.mean(all_metrics, axis=1) # Combinations\n",
    "        \n",
    "        # pick best\n",
    "        best_ix = np.argmin(avg_metric)\n",
    "\n",
    "        best_metric = avg_metric[best_ix]\n",
    "        if best_metric > current_metric:\n",
    "            # no combination improved on current best, stop\n",
    "            break\n",
    "        else:\n",
    "            current_metric = best_metric\n",
    "            best_feature = rem_features[best_ix]\n",
    "            \n",
    "            # update\n",
    "            current_combination = current_combination + [best_feature]\n",
    "\n",
    "            # remove from remaining features\n",
    "            rem_features = [f for f in rem_features if f != best_feature]\n",
    "\n",
    "    return current_combination\n",
    "\n",
    "best_combination = forward_greedy_selection(df, \n",
    "                                            input_cols=features, \n",
    "                                            output_col='Miles_per_Gallon', \n",
    "                                            train_test_factory=mvlr_train_test_function_factory)\n",
    "\n",
    "best_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54af382",
   "metadata": {},
   "source": [
    "# Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a6cb3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Weight_in_lbs', 'Year', 'Origin', 'Horsepower']\n",
      "['Weight_in_lbs', 'Year', 'Origin', 'Acceleration']\n",
      "['Weight_in_lbs', 'Year', 'Origin']\n",
      "['Weight_in_lbs', 'Year', 'Origin']\n",
      "['Weight_in_lbs', 'Year', 'Origin', 'Horsepower', 'Acceleration']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(10.880129732377553)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This ANOTHER factory!\n",
    "# this one performs feature selection and trains the model on the best combination\n",
    "# this is the power of functional composition\n",
    "def feature_selection_train_test_factory(features, output_col, method='greedy'):\n",
    "\n",
    "    # pick the strategy for feature selection based on the method parameter\n",
    "    if method == 'greedy':\n",
    "        feature_selection_fn = forward_greedy_selection\n",
    "    elif method == 'brute':\n",
    "        feature_selection_fn = brute_force_selection\n",
    "    else:\n",
    "        raise Exception(\"Unknown method\")\n",
    "    \n",
    "    def train_test_fn(df_train, df_test):\n",
    "        # find best combination\n",
    "        best_combination = feature_selection_fn(df_train, input_cols=features, output_col=output_col, train_test_factory=mvlr_train_test_function_factory)\n",
    "        print(best_combination)\n",
    "\n",
    "        # fit the model to the whole training dataset\n",
    "        best_p = linear_model_numpy.optimize(df_train[best_combination], df_train[output_col].to_numpy(), learning_rate=0.1, epochs=100)\n",
    "\n",
    "        # evaluate it\n",
    "        yhat = linear_model_numpy.predict(best_p, df_test[best_combination])\n",
    "        ytest = df_test[output_col].to_numpy()\n",
    "        mse = np.mean(np.square(yhat - ytest))\n",
    "        return mse \n",
    "    return train_test_fn\n",
    "\n",
    "train_test_fn = feature_selection_train_test_factory(features, 'Miles_per_Gallon', 'greedy')\n",
    "metrics = cv(df, train_test_fn, folds=5, random_state=23424)\n",
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c2e61",
   "metadata": {},
   "source": [
    "# Why are We Using these Factories?\n",
    "\n",
    "Answer: Reusability.\n",
    "\n",
    "Notice that `cv()` does not know anything about the model being tested, nor do `brute_force_selection` and `forward_greedy_selection` functions. We can use the same functions with other models, which we will do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee277b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
