{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffd671c",
   "metadata": {},
   "source": [
    "# Block 6: Feature Selection\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Enumerate all combinations of features\n",
    "- Implement and test brute force selection\n",
    "- Implement and test forward greedy selection\n",
    "- Use brute force and greedy within the proper nested-CV setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee049e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import itertools\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17567b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copied these functions from block4 and block5\n",
    "#\n",
    "\n",
    "def prepare_inputs(df):\n",
    "    # we need to separate categorical from numeric features\n",
    "    # because they require separate processing\n",
    "    # let's get categorical columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "    \n",
    "    # let's get numeric\n",
    "    ordinal_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "    # construct input features\n",
    "    X = df[ordinal_cols].to_numpy()\n",
    "\n",
    "    # z-score (NxK' - 1xK') / 1xK' = NxK'\n",
    "    X = (X - np.mean(X, axis=0)[None, :]) / np.std(X, axis=0)[None, :]\n",
    "\n",
    "    # code categorical features\n",
    "    for feature in categorical_cols:\n",
    "        dummies = pd.get_dummies(df[feature]).to_numpy().astype(float)\n",
    "        X = np.hstack((X, dummies)) \n",
    "\n",
    "    # add a column of ones\n",
    "    ones_col = np.ones((X.shape[0], 1)) # Nx1\n",
    "    X = np.hstack((ones_col, X)) # K\n",
    "\n",
    "    return X \n",
    "\n",
    "def forward_fn(Beta, X):\n",
    "    \"\"\"\n",
    "        Beta: K\n",
    "        X: NxK\n",
    "    \"\"\"\n",
    "   \n",
    "    return X @ Beta # NxK @ K = N\n",
    "\n",
    "def optimize(df, y, eta, steps):\n",
    "\n",
    "    X = prepare_inputs(df)\n",
    "    \n",
    "    # randomly initialize solution \n",
    "    Beta = np.random.rand(X.shape[1]) # K\n",
    "    \n",
    "    # iterate for steps\n",
    "    history = []\n",
    "\n",
    "    for i in range(steps):\n",
    "        yhat = forward_fn(Beta, X)\n",
    "        mse = np.mean(np.square(yhat - y))\n",
    "        history.append([Beta, mse])\n",
    "\n",
    "        # compute gradient at those predictions\n",
    "        # (NxK).T @ N = K\n",
    "        Beta_grad = 2 * X.T @ (yhat - y) / X.shape[0]\n",
    "        \n",
    "        # update solution\n",
    "        Beta = Beta - eta * Beta_grad\n",
    "        \n",
    "    return Beta, history \n",
    "def predict(Beta, df):\n",
    "    X = prepare_inputs(df)\n",
    "    \n",
    "    return forward_fn(Beta, X)\n",
    "\n",
    "#\n",
    "# this is a function ... that returns a function :)\n",
    "#\n",
    "def create_mvlr_train_test_fn(features, output_col):\n",
    "    \n",
    "    def train_test_fn(df_train, df_test):\n",
    "        params, _ = optimize(df_train[features], df_train[output_col], eta = 0.1, steps=100)\n",
    "        yhat = predict(params, df_test[features])\n",
    "        ytest = df_test[output_col].to_numpy()\n",
    "        mse = np.mean(np.square(yhat - ytest))\n",
    "        return mse \n",
    "\n",
    "    return train_test_fn\n",
    "\n",
    "#\n",
    "# Cross-validation function\n",
    "#\n",
    "def cv(df, train_test_fn, folds, random_state):\n",
    "\n",
    "    # instantiate the splitter\n",
    "    kf = sklearn.model_selection.KFold(n_splits=folds, \n",
    "                                       shuffle=True, \n",
    "                                       random_state=random_state)\n",
    "    \n",
    "    metrics = []\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_df = df.iloc[train_index]\n",
    "        test_df = df.iloc[test_index]\n",
    "        \n",
    "        # evaluate\n",
    "        metric = train_test_fn(train_df, test_df)\n",
    "        metrics.append(metric)\n",
    "    \n",
    "    return metrics \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab58b7",
   "metadata": {},
   "source": [
    "## Brute Force Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b9d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a',), ('b',), ('c',)]\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'c')]\n",
      "[('a', 'b', 'c')]\n",
      "[('a',), ('b',), ('c',), ('a', 'b'), ('a', 'c'), ('b', 'c')]\n"
     ]
    }
   ],
   "source": [
    "# let's play with combinations function because we'll use it in brute force\n",
    "# selection\n",
    "cols = ['a', 'b', 'c']\n",
    "\n",
    "# combinations of length 3\n",
    "print(list(itertools.combinations(cols, 1)))\n",
    "# combinations of length 2\n",
    "print(list(itertools.combinations(cols, 2)))\n",
    "# combinations of length 3\n",
    "print(list(itertools.combinations(cols, 3)))\n",
    "\n",
    "# to get all combinations\n",
    "all_combinations = [comb for i in range(1, len(cols)) for comb in itertools.combinations(cols, i)]\n",
    "print(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f76e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (406, 9)\n",
      "After:  (392, 9)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_json('../data/cars.json')\n",
    "\n",
    "# Filter dataframe\n",
    "required_cols = ['Miles_per_Gallon', 'Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin']\n",
    "\n",
    "# only include rows where ALL columns are not nan\n",
    "ix_included = np.sum(pd.isna(df[required_cols]), axis=1) == 0\n",
    "\n",
    "# exclude examples with no horsepower or mpg\n",
    "print(\"Before: \", df.shape)\n",
    "df = df[ix_included]\n",
    "print(\"After: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae3af3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Horsepower', 'Weight_in_lbs', 'Origin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def brute_force_selection(df,\n",
    "                          input_cols,\n",
    "                          output_col,\n",
    "                          create_train_test_fn):\n",
    "\n",
    "    # generate all combinations\n",
    "    all_combinations = [comb for i in range(1, len(input_cols)) for comb in itertools.combinations(input_cols, i)]\n",
    "\n",
    "    # start cross validation FOR EACH combination\n",
    "    all_metrics = []\n",
    "    for combination in all_combinations:\n",
    "        # important to keep random state the same for all combinations\n",
    "        # so that generated splits are the same\n",
    "        train_test_fn = create_train_test_fn(list(combination), output_col)\n",
    "\n",
    "        metrics = cv(df, train_test_fn, folds=5, random_state=23412341)\n",
    "        all_metrics.append(metrics)\n",
    "    \n",
    "    # organize all results in a 2D matrix (Rows = combinations, cols = folds)\n",
    "    all_metrics = np.array(all_metrics) # Combinations x Folds\n",
    "\n",
    "    # compute average metric for each combination\n",
    "    avg_metric = np.mean(all_metrics, axis=1) # Combinations\n",
    "    \n",
    "    # pick best\n",
    "    best_ix = np.argmin(avg_metric)\n",
    "    best_combination = list(all_combinations[best_ix])\n",
    "    \n",
    "    return best_combination\n",
    "\n",
    "\n",
    "features = ['Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin']\n",
    "\n",
    "best_combination = brute_force_selection(df, input_cols=features, output_col='Miles_per_Gallon', create_train_test_fn=create_mvlr_train_test_fn)\n",
    "\n",
    "best_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680668a",
   "metadata": {},
   "source": [
    "## Forward Greedy Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807ec2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weight_in_lbs', 'Horsepower', 'Origin']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_greedy_selection(df,\n",
    "                             input_cols,\n",
    "                             output_col,\n",
    "                             create_train_test_fn):\n",
    "    \n",
    "    \n",
    "    current_combination = []\n",
    "    current_metric = np.inf\n",
    "    rem_features = input_cols\n",
    "\n",
    "    while len(rem_features) > 0:\n",
    "        \n",
    "        all_metrics = []\n",
    "        for feature in rem_features:\n",
    "            \n",
    "            # create candidate\n",
    "            candidate_combination = current_combination + [feature]\n",
    "\n",
    "            # important to keep random state the same for all combinations\n",
    "            # so that generated splits are the same\n",
    "            train_test_fn = create_train_test_fn(candidate_combination, output_col)\n",
    "\n",
    "            metrics = cv(df, train_test_fn, folds=5, random_state=23412341)\n",
    "            all_metrics.append(metrics)\n",
    "        \n",
    "        # organize all results in a 2D matrix (Rows = Rem Features, cols = folds)\n",
    "        all_metrics = np.array(all_metrics) # Rem Features x Folds\n",
    "\n",
    "        # compute average metric for each combination\n",
    "        avg_metric = np.mean(all_metrics, axis=1) # Combinations\n",
    "        \n",
    "        # pick best\n",
    "        best_ix = np.argmin(avg_metric)\n",
    "\n",
    "        best_metric = avg_metric[best_ix]\n",
    "        if best_metric > current_metric:\n",
    "            # no combination improved on current best, stop\n",
    "            break\n",
    "        else:\n",
    "            current_metric = best_metric\n",
    "            best_feature = rem_features[best_ix]\n",
    "            \n",
    "            # update\n",
    "            current_combination = current_combination + [best_feature]\n",
    "\n",
    "            # remove from remaining features\n",
    "            rem_features = [f for f in rem_features if f != best_feature]\n",
    "\n",
    "    return current_combination\n",
    "\n",
    "best_combination = forward_greedy_selection(df, input_cols=features, output_col='Miles_per_Gallon', create_train_test_fn=create_mvlr_train_test_fn)\n",
    "\n",
    "best_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6cb3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Horsepower', 'Weight_in_lbs', 'Origin']\n",
      "['Horsepower', 'Weight_in_lbs', 'Origin']\n",
      "['Horsepower', 'Weight_in_lbs']\n",
      "['Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin']\n",
      "['Horsepower', 'Weight_in_lbs', 'Origin']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(18.55799991409059)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_feature_selection_train_test_fn(features, output_col, method='greedy'):\n",
    "\n",
    "    # pick the strategy for feature selection based on the method parameter\n",
    "    if method == 'greedy':\n",
    "        feature_selection_fn = forward_greedy_selection\n",
    "    elif method == 'brute':\n",
    "        feature_selection_fn = brute_force_selection\n",
    "    else:\n",
    "        raise Exception(\"Unknown method\")\n",
    "    \n",
    "    def train_test_fn(df_train, df_test):\n",
    "        # find best combination\n",
    "        best_combination = feature_selection_fn(df_train, input_cols=features, output_col=output_col, create_train_test_fn=create_mvlr_train_test_fn)\n",
    "        print(best_combination)\n",
    "\n",
    "        # fit the model to the whole training dataset\n",
    "        best_p, _ = optimize(df_train[best_combination], df_train[output_col].to_numpy(), eta=0.1, steps=100)\n",
    "\n",
    "        # evaluate it\n",
    "        yhat = predict(best_p, df_test[best_combination])\n",
    "        ytest = df_test[output_col].to_numpy()\n",
    "        mse = np.mean(np.square(yhat - ytest))\n",
    "        return mse \n",
    "    return train_test_fn\n",
    "\n",
    "train_test_fn = create_feature_selection_train_test_fn(features, 'Miles_per_Gallon', 'brute')\n",
    "metrics = cv(df, train_test_fn, folds=5, random_state=23424)\n",
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c2e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
