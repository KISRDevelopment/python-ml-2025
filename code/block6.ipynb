{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffd671c",
   "metadata": {},
   "source": [
    "# Block 6: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ee049e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import itertools\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e620b",
   "metadata": {},
   "source": [
    "## Preliminaries: Some Cleanup\n",
    "\n",
    "### Model Class \n",
    "\n",
    "Lets encapsulate our model in a class so that it is more easy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a95d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "\n",
    "    def __init__(self, \n",
    "                 features: List[str]):\n",
    "        self._features = features \n",
    "    \n",
    "    def train(self, df: pd.DataFrame, y: np.ndarray, steps: int = 100, eta: float = 0.01):\n",
    "\n",
    "        # prepare inputs and outputs\n",
    "        X = self._prepare_input_matrix(df[self._features])\n",
    "        \n",
    "        # randomly initialize solution \n",
    "        Beta = np.random.rand(X.shape[1]) # K\n",
    "\n",
    "        # iterate for steps\n",
    "        history = []\n",
    "        for i in range(steps):\n",
    "            # compute model predictions\n",
    "            yhat = X @ Beta # N\n",
    "            mse = np.mean(np.square(yhat - y))\n",
    "            history.append([Beta, mse])\n",
    "\n",
    "            # compute gradient at those predictions\n",
    "            # (NxK).T @ N = K\n",
    "            Beta_grad = 2 * X.T @ (yhat - y) / X.shape[0]\n",
    "            \n",
    "            # update solution\n",
    "            Beta = Beta - eta * Beta_grad\n",
    "        \n",
    "        # save the parameters\n",
    "        self._params, _ = history[-1]\n",
    "\n",
    "        return history\n",
    "    \n",
    "    def _prepare_input_matrix(self, df: pd.DataFrame):\n",
    "\n",
    "        # we need to separate categorical from numeric features\n",
    "        # because they require separate processing\n",
    "        # let's get categorical columns\n",
    "        categorical_cols = df.select_dtypes(include='object').columns\n",
    "        \n",
    "        # let's get numeric\n",
    "        ordinal_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "        # construct input features\n",
    "        X = df[ordinal_cols].to_numpy()\n",
    "\n",
    "        # z-score (NxK' - 1xK') / 1xK' = NxK'\n",
    "        X = (X - np.mean(X, axis=0)[None, :]) / np.std(X, axis=0)[None, :]\n",
    "\n",
    "        # code categorical features\n",
    "        for feature in categorical_cols:\n",
    "            dummies = pd.get_dummies(df[feature]).to_numpy().astype(float)\n",
    "            X = np.hstack((X, dummies)) \n",
    "\n",
    "        # add a column of ones\n",
    "        ones_col = np.ones((X.shape[0], 1)) # Nx1\n",
    "        X = np.hstack((ones_col, X)) # K\n",
    "        \n",
    "        return X \n",
    "    \n",
    "    def predict(self, df: pd.DataFrame):\n",
    "         \n",
    "        X = self._prepare_input_matrix(df[self._features])\n",
    "\n",
    "        # compute model predictions\n",
    "        yhat = X @ self._params # N\n",
    "\n",
    "        return yhat \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3db697",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Let's make it easy to run CV on a model. Notice how the function takes a function that creates a trains a model. This makes the CV function model-agnostic: it does not care what kind of model you pass into it. It just knows that it has to train and evaluate it using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e881cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(df, y, folds, random_state, make_model_func):\n",
    "\n",
    "    kf = sklearn.model_selection.KFold(n_splits=folds, \n",
    "                                       shuffle=True, \n",
    "                                       random_state=random_state)\n",
    "    \n",
    "    features = df.columns.tolist()\n",
    "    mses = []\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_df = df.iloc[train_index]\n",
    "        ytrain = y[train_index]\n",
    "\n",
    "        test_df = df.iloc[test_index]\n",
    "        ytest = y[test_index]\n",
    "\n",
    "        # train and predict\n",
    "        model = make_model_func(train_df[features], ytrain)\n",
    "        yhat = model.predict(test_df[features])\n",
    "        \n",
    "        # evaluate\n",
    "        mse = np.mean(np.square(yhat - ytest))\n",
    "        mses.append(mse)\n",
    "    \n",
    "    return mses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f640ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (406, 9)\n",
      "After:  (392, 9)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_json('../data/cars.json')\n",
    "\n",
    "# Filter dataframe\n",
    "required_cols = ['Miles_per_Gallon', 'Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin']\n",
    "\n",
    "# only include rows where ALL columns are not nan\n",
    "ix_included = np.sum(pd.isna(df[required_cols]), axis=1) == 0\n",
    "\n",
    "# exclude examples with no horsepower or mpg\n",
    "print(\"Before: \", df.shape)\n",
    "df = df[ix_included]\n",
    "print(\"After: \", df.shape)\n",
    "df = df[required_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "257b572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.592350554844835\n",
      "25.592350554844835\n"
     ]
    }
   ],
   "source": [
    "# Let's test the new class \n",
    "model = LinearModel(['Displacement', 'Origin'])\n",
    "history = model.train(df, df[ 'Miles_per_Gallon'].to_numpy())\n",
    "print(history[-1][1])\n",
    "yhat = model.predict(df)\n",
    "mse = np.mean(np.square(yhat - df.Miles_per_Gallon))\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4244c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(21.493534455408774),\n",
       " np.float64(37.92309974601892),\n",
       " np.float64(26.200757294111128),\n",
       " np.float64(20.848371719804636),\n",
       " np.float64(26.572661182072324)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run CV \n",
    "def model_func(df, y):\n",
    "    model = LinearModel(df.columns.tolist())\n",
    "    model.train(df, y)\n",
    "    return model \n",
    "\n",
    "mses = cv(df[['Displacement', 'Origin']], \n",
    "          df['Miles_per_Gallon'].to_numpy(), \n",
    "          folds=5, \n",
    "          random_state=4234,\n",
    "          make_model_func=model_func)\n",
    "mses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab58b7",
   "metadata": {},
   "source": [
    "## Brute Force Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16b9d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a',), ('b',), ('c',)]\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'c')]\n",
      "[('a', 'b', 'c')]\n",
      "[('a',), ('b',), ('c',), ('a', 'b'), ('a', 'c'), ('b', 'c')]\n"
     ]
    }
   ],
   "source": [
    "# let's play with combinations function because we'll use it in brute force\n",
    "# selection\n",
    "cols = ['a', 'b', 'c']\n",
    "\n",
    "# combinations of length 3\n",
    "print(list(itertools.combinations(cols, 1)))\n",
    "# combinations of length 2\n",
    "print(list(itertools.combinations(cols, 2)))\n",
    "# combinations of length 3\n",
    "print(list(itertools.combinations(cols, 3)))\n",
    "\n",
    "# to get all combinations\n",
    "all_combinations = [comb for i in range(1, len(cols)) for comb in itertools.combinations(cols, i)]\n",
    "print(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ae3af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Displacement', 'Weight_in_lbs', 'Origin']\n"
     ]
    }
   ],
   "source": [
    "def brute_force_selection(df,\n",
    "                          y,\n",
    "                          make_model_func):\n",
    "\n",
    "    input_cols = df.columns.tolist()\n",
    "    # generate all combinations\n",
    "    all_combinations = [comb for i in range(1, len(input_cols)) for comb in itertools.combinations(input_cols, i)]\n",
    "\n",
    "    # start cross validation\n",
    "    all_mses = []\n",
    "    for combination in all_combinations:\n",
    "        # important to keep random state the same for all combinations\n",
    "        # so that generated splits are the same\n",
    "        mses = cv(df[list(combination)], \n",
    "                  y, \n",
    "                  folds=5, \n",
    "                  random_state=234234,\n",
    "                  make_model_func=make_model_func)   \n",
    "        all_mses.append(mses)\n",
    "    \n",
    "    # organize all results in a 2D matrix (Rows = combinations, cols = folds)\n",
    "    all_mses = np.array(all_mses) # Combinations x Folds\n",
    "\n",
    "    # compute average MSE for each combination\n",
    "    avg_mse = np.mean(all_mses, axis=1) # Combinations\n",
    "    \n",
    "    # pick best\n",
    "    best_ix = np.argmin(avg_mse)\n",
    "    best_combination = list(all_combinations[best_ix])\n",
    "    \n",
    "    # now train the best combination on the whole dataset and return the fitted model\n",
    "    return make_model_func(df[best_combination], y)\n",
    "\n",
    "\n",
    "\n",
    "model = brute_force_selection(df[['Cylinders', \n",
    "                                   'Displacement', \n",
    "                                   'Horsepower', \n",
    "                                   'Weight_in_lbs', \n",
    "                                   'Acceleration', \n",
    "                                   'Origin']], \n",
    "                                   df['Miles_per_Gallon'].to_numpy(),\n",
    "                                   make_model_func=model_func)\n",
    "print(model._features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e258d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "804f347b",
   "metadata": {},
   "source": [
    "## Full Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8fc6de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(21.006936164915782),\n",
       " np.float64(30.90874707559287),\n",
       " np.float64(24.391832638278693),\n",
       " np.float64(22.0066080216344),\n",
       " np.float64(19.742635857008167)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run CV \n",
    "def linear_model_func(df, y):\n",
    "    model = LinearModel(df.columns.tolist())\n",
    "    model.train(df, y)\n",
    "    return model \n",
    "\n",
    "def bf_linear_model_func(df, y):\n",
    "    return brute_force_selection(df, y, make_model_func=linear_model_func)\n",
    "\n",
    "mses = cv(df[['Cylinders', \n",
    "              'Displacement', \n",
    "              'Horsepower', \n",
    "              'Weight_in_lbs', \n",
    "              'Acceleration', \n",
    "              'Origin']], \n",
    "              df['Miles_per_Gallon'].to_numpy(),\n",
    "              folds=5,\n",
    "              random_state=234243,\n",
    "              make_model_func=bf_linear_model_func)\n",
    "mses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680668a",
   "metadata": {},
   "source": [
    "## Forward Greedy Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ec2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight_in_lbs\n",
      "Origin\n",
      "Displacement\n",
      "['Weight_in_lbs', 'Origin', 'Displacement']\n"
     ]
    }
   ],
   "source": [
    "def greedy_feature_selection(df,\n",
    "                             y,\n",
    "                             make_model_func):\n",
    "    \n",
    "    input_cols = df.columns.tolist()\n",
    "    \n",
    "    current_combination = []\n",
    "    current_mse = np.inf\n",
    "    rem_features = input_cols\n",
    "    while len(rem_features) > 0:\n",
    "        \n",
    "        all_mses = []\n",
    "        for feature in rem_features:\n",
    "            \n",
    "            # create candidate\n",
    "            candidate_combination = current_combination + [feature]\n",
    "\n",
    "            # important to keep random state the same for all combinations\n",
    "            # so that generated splits are the same\n",
    "            mses = cv(df[list(candidate_combination)], \n",
    "                    y, \n",
    "                    folds=5, \n",
    "                    random_state=234234,\n",
    "                    make_model_func=make_model_func)   \n",
    "            all_mses.append(mses)\n",
    "\n",
    "        # organize all results in a 2D matrix (Rows = Rem Features, cols = folds)\n",
    "        all_mses = np.array(all_mses) # Rem Features x Folds\n",
    "\n",
    "        # compute average MSE for each combination\n",
    "        avg_mse = np.mean(all_mses, axis=1) # Combinations\n",
    "        \n",
    "        # pick best\n",
    "        best_ix = np.argmin(avg_mse)\n",
    "\n",
    "        best_mse = avg_mse[best_ix]\n",
    "        if best_mse > current_mse:\n",
    "            # no combination improved on current best, stop\n",
    "            break\n",
    "        else:\n",
    "            current_mse = best_mse\n",
    "            best_feature = rem_features[best_ix]\n",
    "            \n",
    "            # update\n",
    "            current_combination = current_combination + [best_feature]\n",
    "\n",
    "            # remove from remaining features\n",
    "            rem_features = [f for f in rem_features if f != best_feature]\n",
    "\n",
    "    # now train the best combination on the whole dataset and return the fitted model\n",
    "    return make_model_func(df[current_combination], y)\n",
    "\n",
    "model = greedy_feature_selection(df[['Cylinders', \n",
    "                                   'Displacement', \n",
    "                                   'Horsepower', \n",
    "                                   'Weight_in_lbs', \n",
    "                                   'Acceleration', \n",
    "                                   'Origin']], \n",
    "                                   df['Miles_per_Gallon'].to_numpy(),\n",
    "                                   make_model_func=model_func)\n",
    "print(model._features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae4131a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight_in_lbs\n",
      "Origin\n",
      "Displacement\n",
      "Weight_in_lbs\n",
      "Origin\n",
      "Displacement\n",
      "Weight_in_lbs\n",
      "Origin\n",
      "Displacement\n",
      "Weight_in_lbs\n",
      "Origin\n",
      "Displacement\n",
      "Weight_in_lbs\n",
      "Origin\n",
      "Horsepower\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(21.252164484244403),\n",
       " np.float64(31.5298994241853),\n",
       " np.float64(24.70807198189231),\n",
       " np.float64(22.74831049633149),\n",
       " np.float64(19.44312060511264)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gf_linear_model_func(df, y):\n",
    "    return greedy_feature_selection(df, y, make_model_func=linear_model_func)\n",
    "\n",
    "mses = cv(df[['Cylinders', \n",
    "              'Displacement', \n",
    "              'Horsepower', \n",
    "              'Weight_in_lbs', \n",
    "              'Acceleration', \n",
    "              'Origin']], \n",
    "              df['Miles_per_Gallon'].to_numpy(),\n",
    "              folds=5,\n",
    "              random_state=234243,\n",
    "              make_model_func=gf_linear_model_func)\n",
    "mses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cb3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-ml-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
