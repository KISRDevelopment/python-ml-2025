{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe467c78",
   "metadata": {},
   "source": [
    "# Block 5: Evaluation\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Do a single random split and train and test\n",
    "- Use the class to perform cross-validation on the multivariate regression model\n",
    "- Learn how `KFold` class works and helps in cross-validation\n",
    "- Report mean MSE and standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527ce834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d568af",
   "metadata": {},
   "source": [
    "## Single Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8352beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [2 0 1 6 7 4]\n",
      "Test:  [5 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 7, 8, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Quick demo\n",
    "#\n",
    "\n",
    "# Let's define a toy dataset \n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [10, 11], [-1, -2], [0, 0], [3, 3]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "# this is the list of sequential indecies into X (just the length of axis 0 of X)\n",
    "ind = np.arange(X.shape[0])\n",
    "\n",
    "# we shuffle it (this returns a copy)\n",
    "ind = np.random.permutation(ind)\n",
    "\n",
    "# now we take the first 80%\n",
    "prop = 0.8\n",
    "train_len = int(prop * X.shape[0]) # number of training elements (6)\n",
    "\n",
    "# get training and testing indecies\n",
    "train_ind = ind[:train_len]\n",
    "test_ind = ind[train_len:]\n",
    "print(\"Train: \", train_ind)\n",
    "print(\"Test: \", test_ind)\n",
    "\n",
    "# now use them to grab the training and testing portions of X and y\n",
    "X_train = X[train_ind, :] # first 80% of X\n",
    "X_test = X[test_ind, :]\n",
    "ytrain = y[train_ind]\n",
    "ytest = y[test_ind]\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad012e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copied these functions from block4\n",
    "#\n",
    "\n",
    "def prepare_inputs(df):\n",
    "    # we need to separate categorical from numeric features\n",
    "    # because they require separate processing\n",
    "    # let's get categorical columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "    \n",
    "    # let's get numeric\n",
    "    ordinal_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "    # construct input features\n",
    "    X = df[ordinal_cols].to_numpy()\n",
    "\n",
    "    # z-score (NxK' - 1xK') / 1xK' = NxK'\n",
    "    X = (X - np.mean(X, axis=0)[None, :]) / np.std(X, axis=0)[None, :]\n",
    "\n",
    "    # code categorical features\n",
    "    for feature in categorical_cols:\n",
    "        dummies = pd.get_dummies(df[feature]).to_numpy().astype(float)\n",
    "        X = np.hstack((X, dummies)) \n",
    "\n",
    "    # add a column of ones\n",
    "    ones_col = np.ones((X.shape[0], 1)) # Nx1\n",
    "    X = np.hstack((ones_col, X)) # K\n",
    "\n",
    "    return X \n",
    "\n",
    "def forward_fn(Beta, X):\n",
    "    \"\"\"\n",
    "        Beta: K\n",
    "        X: NxK\n",
    "    \"\"\"\n",
    "   \n",
    "    return X @ Beta # NxK @ K = N\n",
    "\n",
    "def optimize(df, y, eta, steps):\n",
    "\n",
    "    X = prepare_inputs(df)\n",
    "    \n",
    "    # randomly initialize solution \n",
    "    Beta = np.random.rand(X.shape[1]) # K\n",
    "    \n",
    "    # iterate for steps\n",
    "    history = []\n",
    "\n",
    "    for i in range(steps):\n",
    "        yhat = forward_fn(Beta, X)\n",
    "        mse = np.mean(np.square(yhat - y))\n",
    "        history.append([Beta, mse])\n",
    "\n",
    "        # compute gradient at those predictions\n",
    "        # (NxK).T @ N = K\n",
    "        Beta_grad = 2 * X.T @ (yhat - y) / X.shape[0]\n",
    "        \n",
    "        # update solution\n",
    "        Beta = Beta - eta * Beta_grad\n",
    "        \n",
    "    return Beta, history \n",
    "def predict(Beta, df):\n",
    "    X = prepare_inputs(df)\n",
    "    \n",
    "    return forward_fn(Beta, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2391af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (406, 9)\n",
      "After:  (392, 9)\n",
      "Test MSE: 26.70546578505351\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_json('../data/cars.json')\n",
    "\n",
    "# Filter dataframe\n",
    "required_cols = ['Miles_per_Gallon', 'Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin']\n",
    "\n",
    "# only include rows where ALL columns are not nan\n",
    "ix_included = np.sum(pd.isna(df[required_cols]), axis=1) == 0\n",
    "\n",
    "# exclude examples with no horsepower or mpg\n",
    "print(\"Before: \", df.shape)\n",
    "df = df[ix_included]\n",
    "print(\"After: \", df.shape)\n",
    "\n",
    "# this is the list of sequential indecies into X (just the length of axis 0 of X)\n",
    "ind = np.arange(df.shape[0])\n",
    "\n",
    "# we shuffle it (this returns a copy)\n",
    "ind = np.random.permutation(ind)\n",
    "\n",
    "train_ind = ind[:train_len]\n",
    "test_ind = ind[train_len:]\n",
    "\n",
    "# create train and test dfs\n",
    "prop = 0.8\n",
    "train_len = int(prop * df.shape[0]) # number of training elements\n",
    "df_train = df.iloc[train_ind]\n",
    "df_test = df.iloc[test_ind]\n",
    "\n",
    "features = ['Cylinders']\n",
    "output_col = 'Miles_per_Gallon'\n",
    "params, _ = optimize(df_train[features], df_train[output_col], eta = 0.1, steps=100)\n",
    "yhat = predict(params, df_test[features])\n",
    "ytest = df_test[output_col].to_numpy()\n",
    "mse = np.mean(np.square(yhat - ytest))\n",
    "print(f\"Test MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fdecd3",
   "metadata": {},
   "source": [
    "### Making training/evaluation more reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1002c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.705465785051246\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this is a function ... that returns a function :)\n",
    "#\n",
    "def create_train_test_fn(features, output_col):\n",
    "    \n",
    "    def train_test_fn(df_train, df_test):\n",
    "        params, _ = optimize(df_train[features], df_train[output_col], eta = 0.1, steps=100)\n",
    "        yhat = predict(params, df_test[features])\n",
    "        ytest = df_test[output_col].to_numpy()\n",
    "        mse = np.mean(np.square(yhat - ytest))\n",
    "        return mse \n",
    "\n",
    "    return train_test_fn\n",
    "\n",
    "train_test_fn = create_train_test_fn(features, output_col)\n",
    "\n",
    "loss = train_test_fn(df_train, df_test)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ff207",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12542f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN index: [0 1 2 4 5 6] TEST index: [3 7]\n",
      "TRAIN index: [0 1 2 3 4 7] TEST index: [5 6]\n",
      "TRAIN index: [0 3 4 5 6 7] TEST index: [1 2]\n",
      "TRAIN index: [1 2 3 4 5 6 7] TEST index: [0]\n",
      "TRAIN index: [0 1 2 3 5 6 7] TEST index: [4]\n"
     ]
    }
   ],
   "source": [
    "# Let's define a toy dataset \n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [10, 11], [-1, -2], [0, 0], [3, 3]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "# use KFold to split the dataset\n",
    "\n",
    "# try using n_splits greater than the number of data points\n",
    "kf = sklearn.model_selection.KFold(n_splits=5, \n",
    "                                   shuffle=True, \n",
    "                                   random_state=43)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN index:\", train_index, \"TEST index:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056b8c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(31.202771479362852), np.float64(27.734259136877203), np.float64(20.89097853293615), np.float64(24.185752934081133), np.float64(16.25489560189607)]\n",
      "24.05373153703068\n",
      "2.32806643949547\n"
     ]
    }
   ],
   "source": [
    "def cv(df, train_test_fn, folds, random_state):\n",
    "\n",
    "    # instantiate the splitter\n",
    "    kf = sklearn.model_selection.KFold(n_splits=folds, \n",
    "                                       shuffle=True, \n",
    "                                       random_state=random_state)\n",
    "    \n",
    "    metrics = []\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_df = df.iloc[train_index]\n",
    "        test_df = df.iloc[test_index]\n",
    "        \n",
    "        # evaluate\n",
    "        metric = train_test_fn(train_df, test_df)\n",
    "        metrics.append(metric)\n",
    "    \n",
    "    return metrics \n",
    "\n",
    "metrics = cv(df, train_test_fn, folds = 5, random_state= 1341341234)\n",
    "print(metrics)\n",
    "print(np.mean(metrics))\n",
    "print(np.std(metrics) / np.sqrt(len(metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42cf307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
