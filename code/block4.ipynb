{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a5a49c",
   "metadata": {},
   "source": [
    "# Bock 4: Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13037fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45cfd219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (406, 9)\n",
      "After:  (392, 9)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_json('../data/cars.json')\n",
    "\n",
    "# Filter dataframe\n",
    "required_cols = ['Miles_per_Gallon', 'Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration', 'Origin']\n",
    "\n",
    "# only include rows where ALL columns are not nan\n",
    "ix_included = np.sum(pd.isna(df[required_cols]), axis=1) == 0\n",
    "\n",
    "# exclude examples with no horsepower or mpg\n",
    "print(\"Before: \", df.shape)\n",
    "df = df[ix_included]\n",
    "print(\"After: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8688bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of categorical encoding\n",
    "s = pd.Series(['Apple', 'Banana', 'Strawberry'])\n",
    "r = pd.get_dummies(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8a2c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.44591836 -0.62211016  0.0938902  -2.22886136 -3.54202547 -0.1744572\n",
      "  0.31257956  1.08054961 -0.02391265]\n",
      "17.02227509140477\n"
     ]
    }
   ],
   "source": [
    "def optimize(X, y, eta, steps):\n",
    "\n",
    "    # z-score (NxK - 1xK) / 1xK = NxK\n",
    "    # this is not quite right because we have some categorical variables\n",
    "    # but we'll let it slide for now\n",
    "    X = (X - np.mean(X, axis=0)[None, :]) / np.std(X, axis=0)[None, :]\n",
    "\n",
    "    # add a column of ones\n",
    "    ones_col = np.ones((X.shape[0], 1)) # Nx1\n",
    "    X = np.hstack((ones_col, X))\n",
    "    \n",
    "    # randomly initialize solution \n",
    "    Beta = np.random.rand(X.shape[1]) # K\n",
    "\n",
    "    # iterate for steps\n",
    "    history = []\n",
    "\n",
    "    for i in range(steps):\n",
    "        # compute model predictions\n",
    "        yhat = X @ Beta # N\n",
    "        mse = np.mean(np.square(yhat - y))\n",
    "        history.append([Beta, mse])\n",
    "\n",
    "        # compute gradient at those predictions\n",
    "        # (NxK).T @ N = K\n",
    "        Beta_grad = 2 * X.T @ (yhat - y) / X.shape[0]\n",
    "        \n",
    "        # update solution\n",
    "        Beta = Beta - eta * Beta_grad\n",
    "        \n",
    "    return history \n",
    "\n",
    "# construct input features\n",
    "numeric_features = ['Cylinders', 'Displacement', 'Horsepower', 'Weight_in_lbs', 'Acceleration']\n",
    "X = df[numeric_features].to_numpy()\n",
    "dummies = pd.get_dummies(df['Origin']).to_numpy().astype(float)\n",
    "X = np.hstack((X, dummies))\n",
    "\n",
    "history = optimize(X, df.Miles_per_Gallon.to_numpy(), 0.1, 100)\n",
    "final_p, final_mse = history[-1]\n",
    "print(final_p)\n",
    "print(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58e79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-ml-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
